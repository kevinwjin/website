<!DOCTYPE HTML>
<html lang="en">
  <!-- HTML metadata -->
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Kevin W. Jin</title>

    <meta name="author" content="Kevin Jin">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">  
  </head>

  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-GCQYH1RDZW"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-GCQYH1RDZW');
  </script>

  <body>
    <!-- Maximum content width set to 1000px instead of 800px -->
    <table style="width:100%;max-width:1000px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">

                <!-- Name -->
                <p class="name" style="text-align: center;">
                  Kevin W. Jin
                </p>

                <!-- Bio -->
                <p>
                  Hello there! I'm a first-year PhD student in the <a href="https://cbb.yale.edu/">Interdepartmental Program in Computational Biology and Biomedical Informatics</a> at Yale University. I am a member of the <a href="https://clinicalnlp.org/">Clinical NLP Lab</a>, a group in the <a href="https://medicine.yale.edu/biomedical-informatics-data-science/">Department of Biomedical Informatics and Data Science</a> at Yale School of Medicine. I am grateful and fortunate to be advised by <a href="https://medicine.yale.edu/profile/hua-xu/">Hua Xu</a>. 
                </p>
                <p>
                  As a data scientist in training, I have diverse academic interests across the emergent field of biomedical informatics<sup><a href="#footnote1" id="ref1">1</a></sup>, but I concentrate on digital psychiatry: investigating mental health with computational and statistical methods.
                </p>
                <p>
                  I was born and partially raised in Dallas, TX but spent much of my childhood in Beijing, China. I returned to Dallas to finish high school and left for Baltimore, MD for my undergraduate work, completing a B.S. in molecular and cellular biology at Johns Hopkins University in 2020. I returned to Dallas once again and underwent a career transition from a pre-medical track to biomedical informatics. This involved the completion of quantitative coursework and dual full-time research assistant positions at the University of Texas at Dallas in the <a href="https://math.utdallas.edu/">Department of Mathematical Sciences</a> and UT Southwestern Medical Center in the <a href="https://qbrc.swmed.edu/">Quantitative Biomedical Research Center</a>. My research experience spans the biophysical properties of cancer, molecular radiation oncology, microfluidic single-cell analysis, statistical shape analysis, and clinical natural language processing.
                </p>
                <p>
                  Outside of research, I'm passionately invested in global affairs (particularly East Asian geopolitics) and military history. My favorite publications are <a href="https://www.economist.com/">The Economist</a>, <a href="https://newyorker.com/">The New Yorker</a>, <a href="https://reuters.com/">Reuters</a>, <a href="https://apnews.com/">The Associated Press</a>, <a href="https://bbc.co.uk/news">BBC News</a>, <a href="https://nytimes.com/">The New York Times</a>, <a href="https://bloomberg.com/">Bloomberg</a>, <a href="https://washingtonpost.com/">The Washington Post</a>, <a href="https://theatlantic.com/">The Atlantic</a>, <a href="https://npr.org/">NPR</a>, and <a href="https://asia.nikkei.com/">Nikkei Asia</a>. I also follow the work of the <a href="https://www.brookings.edu/">Brookings Institution</a>, the <a href="https://carnegieendowment.org/">Carnegie Endowment for International Peace</a>, and the <a href="https://www.csis.org/">Center for Strategic and International Studies</a>.
                </p>
                <p>
                  Ways that I add flavor to my life include reading a truly inordinate amount of news, studying languages<sup><a href="#footnote2" id="ref2">2</a></sup>, baking desserts and cooking way too much Italian/Japanese/Chinese food<sup><a href="#footnote3" id="ref3">3</a></sup>, as well as sparring with other shinai-wielding fanatics at the <a href="https://yalekendo.sites.yale.edu/">Yale Kendo Club</a><sup><a href="#footnote4" id="ref4">4</a></sup>. I'm also active in the <a href="https://www.ygccgradconsulting.org/">Yale Graduate Consulting Club</a>, the <a href="https://www.yalebiotechclub.org/">Yale Biotech Club</a>, the <a href="https://www.facebook.com/jasuyale/">Yale Japanese American Student Union</a>, and the <a href="https://www.yaleahs.com/">Yale Chapter of the Alexander Hamilton Society</a>.
                </p>


                <!-- Links -->
                <p style="text-align:center">
                  <a href="data/bio.txt">Bio</a> &nbsp;/&nbsp;
                  <a href="mailto:kevin.jin@yale.edu">Email</a> &nbsp;/&nbsp;
                  <a href="data/kwj_cv_02-23-24.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=XiWPysAAAAAJ&hl=en">Google Scholar</a> &nbsp;/&nbsp;
                  <a href="https://twitter.com/kevinwjin">Twitter</a> &nbsp;/&nbsp;
                  <a href="https://github.com/kevinwjin/">GitHub</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/kevin-w-jin/">LinkedIn</a>
                </p>
              </td>

              <!-- Profile Photo -->
              <!-- Consider changing width/max-width to 75%, and border-radius to 0% for corners -->
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/profile.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/profile.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
            
          </tbody></table>

          <!-- News and Highlights -->

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:20px;width:75%;vertical-align:middle">
                <h2>News & Highlights</h2>
                  <ul>
                    <li><b>May 2024</b>: My home department, Biomedical Informatics and Data Science, has officially transitioned from a Section to a Department under the steady stewardship of our chair <a href="https://medicine.yale.edu/profile/lucila-ohno-machado/">Lucila Ohno-Machado</a>.</li>

                    <li><b>April 2024</b>: I've officially joined the <strong><a href="https://clinicalnlp.org/">Xu Lab</a></strong> in the Section of Biomedical Informatics and Data Science at <strong>Yale School of Medicine</strong>!</li>

                    <li><b>August 2023</b>: After moving from Dallas to New Haven, I've begun my <strong>PhD in <a href="https://cbb.yale.edu/">Computational Biology and Biomedical Informatics</a></strong> at <strong>Yale University</strong>!</li>

                    <li><b>June 2023</b>: One astonishing year later, I have completed two transformative research experiences under <strong><a href="https://sites.google.com/site/liqiwei2000/">Prof. Qiwei Li</a></strong> at <strong>The University of Texas at Dallas</strong> and <strong><a href="https://profiles.utsouthwestern.edu/profile/85324/guanghua-xiao.html">Prof. Guanghua Xiao</a></strong> at <strong>UT Southwestern Medical Center</strong>. I express my heartfelt gratitude to all of my mentors and friends for the incredible opportunities.</li>
                  </ul>
              </td>
            </tr>
        </td>
      </tr>
    </table>  


      <!-- Research Interests-->
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
          <h2>Research Interests</h2>
          <ul>
            <li><strong>Clinical large language models for psychiatry</strong>: I am interested in developing and applying clinical large language models to clinical text data to improve our understanding of mental health conditions and their treatment.</li>
            
            <li><strong>Wearable data analysis for psychiatry</strong>: I currently investigate psychiatric associations within wearable device data provided by large databanks, such as the <strong><a href="https://allofus.nih.gov/news-events/announcements/research-roundup-all-us-participants-fitbit-data-drive-new-research">NIH All of Us Research Program</a></strong>, and the <strong><a href="https://www.ukbiobank.ac.uk/">UK BioBank</a></strong>.</li>
          </ul>
          </p>
        </td>
      </tr>
    </tbody></table>

    <!-- Publications -->
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:20px;width:75%;vertical-align:middle">
          <h2 id="publications">Selected Publications and Conference Proceedings</h2>

          <!-- <p>Representative papers are <span class="highlight">highlighted</span>.</p> -->
          <p>For a complete list of publications, see my <a href="https://scholar.google.com/citations?user=XiWPysAAAAAJ&hl=en">Google Scholar profile.</a></p>
          <br>
        
      
        <span class="papertitle">Evaluating large language models for complex diagnostic reasoning in clinical psychiatry</span>
          
    <br>
    <b>Kevin W. Jin</b>,
    <a href="https://scholar.google.com.hk/citations?user=UYW7X_0AAAAJ&hl=zh-CN">Qianqian Xie</a>,	
    <a href="https://scholar.google.com.hk/citations?user=EYKXSgUAAAAJ&hl=zh-CN">Lingfei Qian</a>,
    <a href="https://sites.google.com/view/jeffreyzhang">Jeffrey Zhang</a>,
    <a href="https://scholar.google.com.hk/citations?user=SnQ_CycAAAAJ&hl=zh-CN">Jimin Huang</a>,
    <a href="https://scholar.google.com/citations?user=Lz82fPQAAAAJ&hl=en">Yujia Zhou</a>,
    <a href="https://scholar.google.com/citations?user=_Uv5LIAAAAAJ&hl=en">Hua Xu</a>			  
    <br>
          <a href="https://www.cpconf.org/"><em>Computational Psychiatry</em></a>, 2024
    <br>
    <a id="CPC_abstract", onclick="detail_switch(this.id)">abstract</a>
    <div id="CPC_abstract_content" style="display:none;">
    <p></p><strong>Background.</strong> Recent advances in large language models (LLMs) promise a paradigm shift for clinical psychiatry; however, their performance in complex diagnostic reasoning remains unclear.
    <br><br><strong>Methods.</strong> We assessed the diagnostic accuracy of 16 state-of-the-art proprietary and open-source LLMs on 79 clinical psychiatry cases of varying difficulty derived from open-access journals including JAMA, NEJM, and Case Reports in Psychiatry. Models tested were GPT-4o, GPT-4-Turbo, GPT-4, GPT 3.5-Turbo, LLaMA 3 (8B/70B and instruct versions), Mistral (7B v0.3 and instruct version), Meditron (7B/70B), and Me-LLaMA (13B/70B and chat versions). Performance was evaluated using top-n accuracy, measuring if the true diagnosis is among the model’s n predicted diagnoses using GPT-4o.
    <br><br><strong>Results.</strong> GPT-4o achieved the best performance with a top-1 accuracy of 0.54 and a top-10 accuracy of 0.75; LLaMA 3-70b-instruct followed with a top-1 accuracy of 0.46 and a top-10 accuracy of 0.71, the best among open-source LLMs; Me LLaMA-70b-chat, a medical LLM, came second among open-source LLMs with a top-1 accuracy of 0.38 and a top-10 accuracy of 0.56. Generalist proprietary LLMs moderately outperformed open-source LLMs, including those fine-tuned for medicine; however, the generalist LLaMA 3 showed potential for further fine-tuning to psychiatric applications.
    <br><br><strong>Future work.</strong> We acknowledge limitations: only zero-shot performance was tested, and the evaluation dataset was small and potentially overlapped with model training datasets. Future work includes incorporating multi-shot evaluations to mitigate unpredictable model responses, refining and enlarging our dataset with rigorous inclusion criteria defined by psychiatrists, and adding human evaluation. Additionally, we aim to develop a novel open-source LLM based on LLaMA 3 for psychiatry-specific patient and clinician queries, ensuring patient safety through instruction fine-tuning using clinical practice guidelines, case reports, and the Yale-New Haven Health System electronic health record.    
    </div>
    <br>
    <br>    
          
      <a href="https://academic.oup.com/bjr/article/96/1150/20230213/7498934">
        <span class="papertitle">Artificial intelligence in mental healthcare: an overview and future perspectives</span>
          </a>
    <br>
    <b>Kevin W. Jin</b>,
    <a href="https://sites.google.com/site/liqiwei2000/">Qiwei Li</a>,	
    <a href="https://profiles.utsouthwestern.edu/profile/85325/yang-xie.html">Yang Xie</a>,
    <a href="https://profiles.utsouthwestern.edu/profile/85324/guanghua-xiao.html">Guanghua Xiao</a>			  
    <br>
          <a href="https://academic.oup.com/bjr"><em>The British Journal of Radiology</em></a>, 2023
    <br>
    <a id="BJR_abstract", onclick="detail_switch(this.id)">abstract</a>
    /
    <a href="data/bjr_2023.bibtex">bibtex</a>
    <div id="BJR_abstract_content" style="display:none;">
    <p></p>Artificial intelligence is disrupting the field of mental healthcare through applications in computational psychiatry, which leverages quantitative techniques to inform our understanding, detection, and treatment of mental illnesses. This paper provides an overview of artificial intelligence technologies in modern mental healthcare and surveys recent advances made by researchers, focusing on the nascent field of digital psychiatry. We also consider the ethical implications of artificial intelligence playing a greater role in mental healthcare.
    </div>
    <br>
    <br>
      <!-- <a href="https://aclanthology.org/2023.eacl-main.36/"><b>PANCETTA: Phoneme Aware Neural Completion to Elicit Tongue Twisters Automatically</b>
          </a>
    <br>
    <a href="https://scholar.google.ca/citations?user=IMYgXsYAAAAJ&hl=en">Sedrick Scott Keh</a>,
    <b>Steven Y. Feng</b>*,
    <a href="https://scholar.google.com/citations?user=rWZq2nQAAAAJ&hl=en">Varun Gangal</a>*,
    <a href="https://scholar.google.com/citations?user=w24_ETkAAAAJ&hl=en">Malihe Alikhani</a>,
    <a href="https://scholar.google.com/citations?user=PUFxrroAAAAJ&hl=en">Eduard Hovy</a>
    <br>
          Proceedings of <em><b>European Chapter of the Association for Computational Linguistics (EACL) 2023</b></em>
    <br>
    <a id="TT_abstract", onclick="detail_switch(this.id)">Abstract</a>
    /
    <a id="TT_bib", onclick="detail_switch(this.id)">Bibtex</a>
    /
    <a href="https://github.com/sedrickkeh/PANCETTA">GitHub</a>
    <div id="TT_abstract_content" style="display:none;">
    <p></p>Tongue twisters are meaningful sentences that are difficult to pronounce. The process of automatically generating tongue twisters is challenging since the generated utterance must satisfy two conditions at once: phonetic difficulty and semantic meaning. Furthermore, phonetic difficulty is itself hard to characterize and is expressed in natural tongue twisters through a heterogeneous mix of phenomena such as alliteration and homophony. In this paper, we propose PANCETTA: Phoneme Aware Neural Completion to Elicit Tongue Twisters Automatically. We leverage phoneme representations to capture the notion of phonetic difficulty, and we train language models to generate original tongue twisters on two proposed task settings. To do this, we curate a dataset called PANCETTA, consisting of existing English tongue twisters. Through automatic and human evaluation, as well as qualitative analysis, we show that PANCETTA generates novel, phonetically difficult, fluent, and semantically meaningful tongue twisters.
          </div>
    <div id="TT_bib_content" style="font-family:monospace;display:none;">
          <p></p>
    @inproceedings{keh-etal-2023-pancetta,
      title = "{PANCETTA}: Phoneme Aware Neural Completion to Elicit Tongue Twisters Automatically",
      author = "Keh, Sedrick Scott  and
        Feng, Steven Y.  and
        Gangal, Varun  and
        Alikhani, Malihe  and
        Hovy, Eduard",
      editor = "Vlachos, Andreas  and
        Augenstein, Isabelle",
      booktitle = "Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics",
      month = may,
      year = "2023",
      address = "Dubrovnik, Croatia",
      publisher = "Association for Computational Linguistics",
      url = "https://aclanthology.org/2023.eacl-main.36",
      doi = "10.18653/v1/2023.eacl-main.36",
      pages = "491--504"}
    </div> 
    <br>
    <br>
      <a href="https://aclanthology.org/2022.coling-1.547/"><b>PINEAPPLE: Personifying INanimate Entities by Acquiring Parallel Personification data for Learning Enhanced generation</b>
          </a>
    <br>
    <a href="https://scholar.google.ca/citations?user=IMYgXsYAAAAJ&hl=en">Sedrick Scott Keh</a>,
    <a href="https://kevin-lu.tech/">Kevin Lu</a>,
    <a href="https://scholar.google.com/citations?user=rWZq2nQAAAAJ&hl=en">Varun Gangal</a>*,
    <b>Steven Y. Feng</b>*,
    <a href="https://scholar.google.co.in/citations?user=YQe9pdUAAAAJ&hl=en">Harsh Jhamtani</a>,
    <a href="https://scholar.google.com/citations?user=w24_ETkAAAAJ&hl=en">Malihe Alikhani</a>,
    <a href="https://scholar.google.com/citations?user=PUFxrroAAAAJ&hl=en">Eduard Hovy</a>
    <br>
          Proceedings of <em><b>International Conference on Computational Linguistics (COLING) 2022</b></em>
    <br>
    Abstract at <em><b>TADA 2021: Conference on New Directions in Analyzing Text as Data</b></em>
    <br>
    <a id="PERSONIF_abstract", onclick="detail_switch(this.id)">Abstract</a>
    /
    <a id="PERSONIF_bib", onclick="detail_switch(this.id)">Bibtex</a>
    /
    <a href="https://github.com/sedrickkeh/PINEAPPLE">GitHub</a>
    /
    <a href="https://www.youtube.com/watch?v=MH1I2EVaZxk">Talk</a>
    /
    <a href="data/sedrick_keh_PINEAPPLE_slides.pdf">Presentation Slides</a>
    /
    <a href="data/sedrick_keh_PINEAPPLE_poster.pdf">Poster</a>
    <div id="PERSONIF_abstract_content" style="display:none;">
    <p></p>A personification is a figure of speech that endows inanimate entities with properties and actions typically seen as requiring animacy. In this paper, we explore the task of personification generation. To this end, we propose PINEAPPLE: Personifying INanimate Entities by Acquiring Parallel Personification data for Learning Enhanced generation. We curate a corpus of personifications called PersonifCorp, together with automatically generated de-personified literalizations of these personifications. We demonstrate the usefulness of this parallel corpus by training a seq2seq model to personify a given literal input. Both automatic and human evaluations show that fine-tuning with PersonifCorp leads to significant gains in personification-related qualities such as animacy and interestingness. A detailed qualitative analysis also highlights key strengths and imperfections of PINEAPPLE over baselines, demonstrating a strong ability to generate diverse and creative personifications that enhance the overall appeal of a sentence.
          </div>
    <div id="PERSONIF_bib_content" style="font-family:monospace;display:none;">
          <p></p>
    @inproceedings{keh-etal-2022-pineapple,
      title = "{PINEAPPLE}: Personifying {IN}animate Entities by Acquiring Parallel Personification Data for Learning Enhanced Generation",
      author = "Keh, Sedrick Scott and Lu, Kevin and Gangal, Varun and Feng, Steven Y. and Jhamtani, Harsh and Alikhani, Malihe and Hovy, Eduard",
      booktitle = "Proceedings of the 29th International Conference on Computational Linguistics",
      month = oct,
      year = "2022",
      address = "Gyeongju, Republic of Korea",
      publisher = "International Committee on Computational Linguistics",
      url = "https://aclanthology.org/2022.coling-1.547",
      pages = "6270--6284"}
    </div> 
    <br>
    <br>
    <a href="https://ojs.aaai.org/index.php/AAAI/article/view/21306"><b>Retrieve, Caption, Generate: Visual Grounding for Enhancing Commonsense in Text Generation Models</b></a>
          </a>
    <br>
    <b>Steven Y. Feng</b>,
    <a href="https://kevin-lu.tech/">Kevin Lu</a>,
    Zhuofu Tao,
    <a href="https://scholar.google.com/citations?user=w24_ETkAAAAJ&hl=en">Malihe Alikhani</a>,
    <a href="https://scholar.google.com/citations?user=gjsxBCkAAAAJ&hl=en">Teruko Mitamura</a>,
    <a href="https://scholar.google.com/citations?user=PUFxrroAAAAJ&hl=en">Eduard Hovy</a>,
    <a href="https://scholar.google.com/citations?user=rWZq2nQAAAAJ&hl=en">Varun Gangal</a>
    <br>
          Proceedings of <em><b>AAAI Conference on Artificial Intelligence 2022</b></em> (Acceptance rate: <b>15%</b>)
    <br>
    Accepted to <em><b>AKBC 2021 Commonsense Reasoning and Knowledge Bases (CSKB) Workshop</b></em>.
          <br>
    <a id="CAPTIONING_abstract", onclick="detail_switch(this.id)">Abstract</a>
    /
    <a id="CAPTIONING_bib", onclick="detail_switch(this.id)">Bibtex</a>
    /
    <a href="https://github.com/styfeng/VisCTG">GitHub</a>
    /
    <a href="data/steven_feng_VisCTG_slides.pdf">Presentation Slides</a>
    /
    <a href="data/steven_feng_VisCTG_poster.pdf">Poster</a>
    <div id="CAPTIONING_abstract_content" style="display:none;">
    <p></p>We investigate the use of multimodal information contained in images as an effective method for enhancing the commonsense of Transformer models for text generation. We perform experiments using BART and T5 on concept-to-text generation, specifically the task of generative commonsense reasoning, or CommonGen. We call our approach VisCTG: Visually Grounded Concept-to-Text Generation. VisCTG involves captioning images representing appropriate everyday scenarios, and using these captions to enrich and steer the generation process. Comprehensive evaluation and analysis demonstrate that VisCTG noticeably improves model performance while successfully addressing several issues of the baseline generations, including poor commonsense, fluency, and specificity.
          </div>
    <div id="CAPTIONING_bib_content" style="font-family:monospace;display:none;">
          <p></p>
    @article{Feng_Lu_Tao_Alikhani_Mitamura_Hovy_Gangal_2022,
    title={Retrieve, Caption, Generate: Visual Grounding for Enhancing Commonsense in Text Generation Models},
    volume={36},
    url={https://ojs.aaai.org/index.php/AAAI/article/view/21306},
    DOI={10.1609/aaai.v36i10.21306},
    number={10},
    journal={Proceedings of the AAAI Conference on Artificial Intelligence},
    author={Feng, Steven Y. and Lu, Kevin and Tao, Zhuofu and Alikhani, Malihe and Mitamura, Teruko and Hovy, Eduard and Gangal, Varun},
    year={2022},
    month={Jun.},
    pages={10618-10626}}
    </div>
    <br>
    <br>
    <a href="https://ojs.aaai.org/index.php/AAAI/article/view/21309">
            <b>NAREOR: The Narrative Reordering Problem</b>
          </a>
    <br>
    <a href="https://scholar.google.com/citations?user=rWZq2nQAAAAJ&hl=en">Varun Gangal</a>*,
    <b>Steven Y. Feng</b>*,
    <a href="https://scholar.google.com/citations?user=w24_ETkAAAAJ&hl=en">Malihe Alikhani</a>,
    <a href="https://scholar.google.com/citations?user=gjsxBCkAAAAJ&hl=en">Teruko Mitamura</a>,
    <a href="https://scholar.google.com/citations?user=PUFxrroAAAAJ&hl=en">Eduard Hovy</a>
    <br>
          Proceedings of <em><b>AAAI Conference on Artificial Intelligence 2022</b></em> (Acceptance rate: <b>15%</b>)
          <br>
    <a id="NAREOR_abstract", onclick="detail_switch(this.id)">Abstract</a>
    /
    <a id="NAREOR_bib", onclick="detail_switch(this.id)">Bibtex</a>
    /
    <a href="https://github.com/vgtomahawk/NAREORCamReady">GitHub</a>
    /
    <a href="data/varun_gangal_NAREOR_slides.pdf">Presentation Slides</a>
    /
    <a href="data/varun_gangal_NAREOR_poster.pdf">Poster</a>
    <div id="NAREOR_abstract_content" style="display:none;">
    <p></p>Many implicit inferences exist in text depending on how it is structured that can critically impact the text's interpretation and meaning. One such structural aspect present in text with chronology is the order of its presentation. For narratives or stories, this is known as the narrative order. Reordering a narrative can impact the temporal, causal, event-based, and other inferences readers draw from it, which in turn can have strong effects both on its interpretation and interestingness. In this paper, we propose and investigate the task of Narrative Reordering (NAREOR) which involves rewriting a given story in a different narrative order while preserving its plot. We present a dataset, NAREORC, with human rewritings of stories within ROCStories in non-linear orders, and conduct a detailed analysis of it. Further, we propose novel task-specific training methods with suitable evaluation metrics. We perform experiments on NAREORC using state-of-the-art models such as BART and T5 and conduct extensive automatic and human evaluations. We demonstrate that although our models can perform decently, NAREOR is a challenging task with potential for further exploration. We also investigate two applications of NAREOR: generation of more interesting variations of stories and serving as adversarial sets for temporal/event-related tasks, besides discussing other prospective ones, such as for pedagogical setups related to language skills like essay writing and applications to medicine involving clinical narratives.
          </div>
    <div id="NAREOR_bib_content" style="font-family:monospace;display:none;">
          <p></p>
    @article{Gangal_Feng_Alikhani_Mitamura_Hovy_2022,
    title={NAREOR: The Narrative Reordering Problem},
    volume={36},
    url={https://ojs.aaai.org/index.php/AAAI/article/view/21309},
    DOI={10.1609/aaai.v36i10.21309},
    number={10},
    journal={Proceedings of the AAAI Conference on Artificial Intelligence},
    author={Gangal, Varun and Feng, Steven Y. and Alikhani, Malihe and Mitamura, Teruko and Hovy, Eduard},
    year={2022},
    month={Jun.},
    pages={10645-10653}}
    </div>
    <br>
    <br>
    <a href="https://aclanthology.org/2021.inlg-1.21/">
            <b>SAPPHIRE: Approaches for Enhanced Concept-to-Text Generation</b>
          </a>
    <br>
    <b>Steven Y. Feng</b>,
    Jessica Huynh,
    Chaitanya Narisetty,
    <a href="https://scholar.google.com/citations?user=PUFxrroAAAAJ&hl=en">Eduard Hovy</a>,
    <a href="https://scholar.google.com/citations?user=rWZq2nQAAAAJ&hl=en">Varun Gangal</a>
    <br>
          Proceedings of <em><b>International Conference on Natural Language Generation (INLG) 2021</b></em> <b><a href="images/INLG_certificate.png"><font color="red">[Best Long Paper]</font></a></b>
          <br>
    <a id="SAPPHIRE_abstract", onclick="detail_switch(this.id)">Abstract</a>
    /
    <a id="SAPPHIRE_bib", onclick="detail_switch(this.id)">Bibtex</a>
    /
    <a href="https://github.com/styfeng/SAPPHIRE">GitHub</a>
    /
    <a href="data/steven_feng_SAPPHIRE_poster.pdf">Poster</a>
    <div id="SAPPHIRE_abstract_content" style="display:none;">
    <p></p>We motivate and propose a suite of simple but effective improvements for concept-to-text generation called SAPPHIRE: Set Augmentation and Post-hoc PHrase Infilling and REcombination. We demonstrate their effectiveness on generative commonsense reasoning, a.k.a the CommonGen task, through experiments using both BART and T5 models. Through extensive automatic and human evaluation, we show that SAPPHIRE noticeably improves model performance. An in-depth qualitative analysis illustrates that SAPPHIRE effectively addresses many issues of the baseline model generations, including lack of commonsense, insufficient specificity, and poor fluency.
          </div>
    <div id="SAPPHIRE_bib_content" style="font-family:monospace;display:none;">
          <p></p>
    @inproceedings{feng-etal-2021-sapphire,
      title = "{SAPPHIRE}: Approaches for Enhanced Concept-to-Text Generation",
      author = "Feng, Steven  and
        Huynh, Jessica  and
        Narisetty, Chaitanya Prasad  and
        Hovy, Eduard  and
        Gangal, Varun",
      booktitle = "Proceedings of the 14th International Conference on Natural Language Generation",
      month = aug,
      year = "2021",
      address = "Aberdeen, Scotland, UK",
      publisher = "Association for Computational Linguistics",
      url = "https://aclanthology.org/2021.inlg-1.21",
      pages = "212--225"}
    </div>
    <br>
    <br>
    <a href="https://aclanthology.org/2021.findings-acl.84/">
            <b>A Survey of Data Augmentation Approaches for NLP</b>
          </a>
    <br>
    <b>Steven Y. Feng</b>*,
    <a href="https://scholar.google.com/citations?user=rWZq2nQAAAAJ&hl=en">Varun Gangal</a>*,
    <a href="https://scholar.google.com/citations?user=wA5TK_0AAAAJ&hl=en">Jason Wei</a>,
    <a href="https://scholar.google.co.in/citations?user=yxWtZLAAAAAJ&hl=en">Sarath Chandar</a>,
    <a href="https://scholar.google.ca/citations?user=45DAXkwAAAAJ&hl=en">Soroush Vosoughi</a>,
    <a href="https://scholar.google.com/citations?user=gjsxBCkAAAAJ&hl=en">Teruko Mitamura</a>,
    <a href="https://scholar.google.com/citations?user=PUFxrroAAAAJ&hl=en">Eduard Hovy</a>
    <br>
          Proceedings of <em><b>Association for Computational Linguistics (ACL) 2021 Findings</b></em> [Long Paper]
          <br>
    <a id="d4nlpsurvey_abstract", onclick="detail_switch(this.id)">Abstract</a>
    /
    <a id="d4nlpsurvey_bib", onclick="detail_switch(this.id)">Bibtex</a>
    /
    <a href="https://github.com/styfeng/DataAug4NLP">GitHub</a>
    /
    <a href="https://www.youtube.com/watch?v=qmqyT_97Poc&ab_channel=GradientFlow">Podcast (with Ed Hovy)</a>
    /
    <a href="https://www.youtube.com/watch?v=kNBVesKUZCk&ab_channel=StevenFeng">Talk (for Google Research)</a>
    /
    <a href="data/steven_feng_google_slides.pdf">Presentation Slides</a>
    /
    <a href="data/steven_feng_ACL_findings_poster.pdf">Poster</a>
    <div id="d4nlpsurvey_abstract_content" style="display:none;">
    <p></p>Data augmentation has recently seen increased interest in NLP due to more work in low-resource domains, new tasks, and the popularity of large-scale neural networks that require large amounts of training data. Despite this recent upsurge, this area is still relatively underexplored, perhaps due to the challenges posed by the discrete nature of language data. In this paper, we present a comprehensive and unifying survey of data augmentation for NLP by summarizing the literature in a structured manner. We first introduce and motivate data augmentation for NLP, and then discuss major methodologically representative approaches. Next, we highlight techniques that are used for popular NLP applications and tasks. We conclude by outlining current challenges and directions for future research. Overall, our paper aims to clarify the landscape of existing literature in data augmentation for NLP and motivate additional work in this area. We also present a GitHub repository with a paper list that will be continuously updated at <a href="https://github.com/styfeng/DataAug4NLP">this link</a>.
          </div>
    <div id="d4nlpsurvey_bib_content" style="font-family:monospace;display:none;">
          <p></p>@inproceedings{feng-etal-2021-survey,
title = "A Survey of Data Augmentation Approaches for {NLP}",
author = "Feng, Steven Y.  and
  Gangal, Varun  and
  Wei, Jason  and
  Chandar, Sarath  and
  Vosoughi, Soroush  and
  Mitamura, Teruko  and
  Hovy, Eduard",
booktitle = "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021",
month = aug,
year = "2021",
address = "Online",
publisher = "Association for Computational Linguistics",
url = "https://aclanthology.org/2021.findings-acl.84",
doi = "10.18653/v1/2021.findings-acl.84",
pages = "968--988"}
    </div>
    <br>
    <br>
      <a href="https://aclanthology.org/2020.deelio-1.4/">
            <b>GenAug: Data Augmentation for Finetuning Text Generators</b>
          </a>
    <br>
    <b>Steven Y. Feng</b>*,
    <a href="https://scholar.google.com/citations?user=rWZq2nQAAAAJ&hl=en">Varun Gangal</a>*,
    <a href="https://scholar.google.com/citations?user=fMKZOjwAAAAJ&hl=en">Dongyeop Kang</a>,
    <a href="https://scholar.google.com/citations?user=gjsxBCkAAAAJ&hl=en">Teruko Mitamura</a>,
    <a href="https://scholar.google.com/citations?user=PUFxrroAAAAJ&hl=en">Eduard Hovy</a>
    <br>
          Proceedings of <em><b>EMNLP 2020 Deep Learning Inside Out (DeeLIO) Workshop</b></em> [Long Paper]
          <br>
    <a id="deelio_abstract", onclick="detail_switch(this.id)">Abstract</a>
     / 
    <a id="deelio_bib", onclick="detail_switch(this.id)">Bibtex</a>
    /
    <a href="https://github.com/styfeng/GenAug">GitHub</a>
    /
    <a href="data/steven_feng_GenAug_slides.pdf">Presentation Slides</a>
    <div id="deelio_abstract_content" style="display:none;">
    <p></p>In this paper, we investigate data augmentation for text generation, which we call GenAug. Text generation and language modeling are important tasks within natural language processing, and are especially challenging for low-data regimes. We propose and evaluate various augmentation methods, including some that incorporate external knowledge, for finetuning GPT-2 on a subset of Yelp Reviews. We also examine the relationship between the amount of augmentation and the quality of the generated text. We utilize several metrics that evaluate important aspects of the generated text including its diversity and fluency. Our experiments demonstrate that insertion of character-level synthetic noise and keyword replacement with hypernyms are effective augmentation methods, and that the quality of generations improves to a peak at approximately three times the amount of original data.
          </div>
    <div id="deelio_bib_content" style="font-family:monospace;display:none;">
          <p></p>@inproceedings{feng-etal-2020-genaug,
title = "{G}en{A}ug: Data Augmentation for Finetuning Text Generators",
author = "Feng, Steven Y.  and
  Gangal, Varun  and
  Kang, Dongyeop  and
  Mitamura, Teruko  and
  Hovy, Eduard",
booktitle = "Proceedings of Deep Learning Inside Out (DeeLIO): The First Workshop on Knowledge Extraction and Integration for Deep Learning Architectures",
month = nov,
year = "2020",
address = "Online",
publisher = "Association for Computational Linguistics",
url = "https://www.aclweb.org/anthology/2020.deelio-1.4",
doi = "10.18653/v1/2020.deelio-1.4",
pages = "29--42"}
          </div>
    <br>
    <br>
    <a href="https://ojs.aaai.org/index.php/AAAI/article/view/6328/">
            <b>ALOHA: Artificial Learning of Human Attributes for Dialogue Agents</b>
          </a>
    <br>
    Aaron W. Li,
    <a href="https://www.linkedin.com/in/veronica-rong-jiang/">Veronica Jiang</a>*,
    <b>Steven Y. Feng</b>*,
    <a href="https://www.linkedin.com/in/julia-sprague/">Julia Sprague</a>,
    Wei Zhou, 
    <a href="https://scholar.google.ca/citations?user=YcBGOtQAAAAJ&hl=en">Jesse Hoey</a>
    <br>
          Proceedings of <em><b>AAAI Conference on Artificial Intelligence 2020</b></em> (Acceptance rate: <b>20.6%</b>) [Oral]
          <br>
    <a id="aaai_abstract", onclick="detail_switch(this.id)">Abstract</a>
     / 
    <a id="aaai_bib", onclick="detail_switch(this.id)">Bibtex</a>
    /
    <a href="https://github.com/newpro/aloha-chatbot">GitHub</a>
    <div id="aaai_abstract_content" style="display:none;">
    <p></p>For conversational AI and virtual assistants to communicate with humans in a realistic way, they must exhibit human characteristics such as expression of emotion and personality. Current attempts toward constructing human-like dialogue agents have presented significant difficulties. We propose Human Level Attributes (HLAs) based on tropes as the basis of a method for learning dialogue agents that can imitate the personalities of fictional characters. Tropes are characteristics of fictional personalities that are observed recurrently and determined by viewers' impressions. By combining detailed HLA data with dialogue data for specific characters, we present a dataset, HLA-Chat, that models character profiles and gives dialogue agents the ability to learn characters' language styles through their HLAs. We then introduce a three-component system, ALOHA (which stands for Artificial Learning of Human Attributes), that combines character space mapping, character community detection, and language style retrieval to build a character (or personality) specific language model. Our preliminary experiments demonstrate that two variations of ALOHA, combined with our proposed dataset, can outperform baseline models at identifying the correct dialogue responses of chosen target characters, and are stable regardless of the character's identity, the genre of the show, and the context of the dialogue.
          </div>
    <div id="aaai_bib_content" style="font-family:monospace;display:none;">
          <p></p>@article{Li_2020,
title={ALOHA: Artificial Learning of Human Attributes for Dialogue Agents},
volume={34},
ISSN={2159-5399},
url={http://dx.doi.org/10.1609/aaai.v34i05.6328},
DOI={10.1609/aaai.v34i05.6328},
number={05},
journal={Proceedings of the AAAI Conference on Artificial Intelligence},
publisher={Association for the Advancement of Artificial Intelligence (AAAI)},
author={Li, Aaron W. and Jiang, Veronica and Feng, Steven Y. and Sprague, Julia and Zhou, Wei and Hoey, Jesse},
year={2020},
month={Apr},
pages={8155–8163}}
          </div>
    <br>
    <br>
    <a href="https://www.aclweb.org/anthology/D19-1272/">
            <b>Keep Calm and Switch On! Preserving Sentiment and Fluency in Semantic Text Exchange</b>
          </a>
    <br>
    <b>Steven Y. Feng</b>*, 
    Aaron W. Li*,
    <a href="https://scholar.google.ca/citations?user=YcBGOtQAAAAJ&hl=en">Jesse Hoey</a>
    <br>
          Proceedings of <em><b>Empirical Methods in Natural Language Processing (EMNLP) 2019</b></em> (Acceptance rate: <b>23.8%</b>) [Long Paper]
          <br>
    <a id="emnlp_abstract", onclick="detail_switch(this.id)">Abstract</a>
     / 
    <a id="emnlp_bib", onclick="detail_switch(this.id)">Bibtex</a>
     / 
    <a href="https://github.com/styfeng/SMERTI">GitHub</a>
    /
    <a href="data/steven_feng_SMERTI_poster.pdf">Poster</a>
    /
    <a href="https://cs.uwaterloo.ca/news/steven-feng-aaron-li-jesse-hoey-develop-virtual-assistants">News Article</a>
    <div id="emnlp_abstract_content" style="display:none;">
   <p></p>In this paper, we present a novel method for measurably adjusting the semantics of text while preserving its sentiment and fluency, a task we call semantic text exchange. This is useful for text data augmentation and the semantic correction of text generated by chatbots and virtual assistants. We introduce a pipeline called SMERTI that combines entity replacement, similarity masking, and text infilling. We measure our pipeline’s success by its Semantic Text Exchange Score (STES): the ability to preserve the original text’s sentiment and fluency while adjusting semantic content. We propose to use masking (replacement) rate threshold as an adjustable parameter to control the amount of semantic change in the text. Our experiments demonstrate that SMERTI can outperform baseline models on Yelp reviews, Amazon reviews, and news headlines.
          </div>
    <div id="emnlp_bib_content" style="font-family:monospace;display:none;">
          <p></p>@inproceedings{feng-etal-2019-keep,
title = "Keep Calm and Switch On! Preserving Sentiment and Fluency in Semantic Text Exchange",
author = "Feng, Steven Y.  and
  Li, Aaron W.  and
  Hoey, Jesse",
booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
month = nov,
year = "2019",
address = "Hong Kong, China",
publisher = "Association for Computational Linguistics",
url = "https://www.aclweb.org/anthology/D19-1272",
doi = "10.18653/v1/D19-1272",
pages = "2701--2711"}
          </div>
    <br>
    <br> -->
    <br>
    * Denotes equal contribution.
  </td>
      </tr>
  </td>
</tr>
</table>

    <!-- Talks, Workshops, & Lectures -->
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:20px;width:75%;vertical-align:middle">
          <h2>Talks, Workshops, & Lectures</h2>
          <p>
            <b>April 2024:</b> I delivered a talk on <strong><a href="https://docs.google.com/presentation/d/1tKGItu7zn_IJnvow5PIAzip04nmbS2mRor37VxW5y68/edit?usp=sharing">modeling psychiatric phenotypes from wearable accelerometer data derived from the UK BioBank</a></strong> for the <a href="https://www.instagram.com/p/C59jknxpkQr/">Bridging GAPS Diversity in STEM Symposium</a> at Yale! This work was conducted as part of my research rotation through <a href="https://www.gersteinlab.org/">Mark Gerstein's lab</a> in my first year.
          </p>
          <p>
        <b>March 2024</b>: I led a workshop on utilizing <strong>McCleary</strong>, a high-performance computing cluster operated by the <a href="https://research.computing.yale.edu/">Yale Center for Research Computing</a>. This was the second of four workshops in the <strong><a href="https://docs.google.com/document/d/1g0gqTX_qrnYFpCHhL1-Q_V3T2CstWHCOfqRWA6D-lxk/edit?usp=sharing">From Milliliters to Megabytes (M2M): Intro to Data Management and Computing Series</a></strong>, organized by the <a href="https://medicine.yale.edu/bbs/diversity/ybdic/">Yale BBS Diversity and Inclusion Collective</a>. Slides <a href="https://docs.google.com/presentation/d/1Mc5ScLEQljwVwFBRr55ZF6P0jFwHN_B5aOHUll17mHs/edit?usp=sharing">here</a>. The audience was comprised of graduate students and medical students of all backgrounds. We had a full room (approx. 30 in attendance) and around 10 on Zoom! 
      </p>
      
        <!-- <br>
        <br>
        <b>July 2021</b>: <a href="https://www.cs.cmu.edu/~hovy/">Eduard Hovy</a> and I were on <b><a href="https://thedataexchange.media/">The Data Exchange Podcast</a></b> with Ben Lorica. We discuss data augmentation for NLP (inspired by our <a href="https://aclanthology.org/2021.findings-acl.84/">survey paper</a>) and challenges + future directions in NLP and machine learning research. Audio and notes <a href="https://thedataexchange.media/data-augmentation-in-natural-language-processing/">here</a>.
        <br>
        <br>
        <iframe width="400" height="250"
        src="https://www.youtube.com/embed/qmqyT_97Poc">
        </iframe>
        <br>
        <br>
        <b>Aug. 2021</b>: <a href="https://vgtomahawk.github.io/">Varun</a> and I gave a talk (to over 100 attendees) for <b>Google Research</b> about data augmentation for NLP (inspired by our <a href="https://aclanthology.org/2021.findings-acl.84/">survey paper</a>). We also touch upon <a href="https://gem-benchmark.com/nl_augmenter">NL-Augmenter</a> and our <a href="https://ctrlgenworkshop.github.io/">CtrlGen Workshop</a> at NeurIPS 2021.
        <br>
        <br>
        <iframe width="400" height="250"
        src="https://www.youtube.com/embed/kNBVesKUZCk">
        </iframe>
        <br>
        <br> -->
      </td>
          </tr>
      </td>
    </tr>
  </table>

  

    <!-- Footnotes -->
    <table width="95%" align="center" border="0" cellspacing="0" cellpadding="0">
      <tbody>

        <tr>
          <td>
            <h2>Footnotes</h2>
            <div id="footnotes">
              <p id="footnote1"><sup>1</sup> Broadly construed, biomedical informatics refers to the computational analysis and statistical interpretation of biological and clinical data. <a href="#ref1" title="Return to footnote 1.">↩</a></p>
              <p id="footnote2"><sup>2</sup> Japanese (intermediate), Mandarin Chinese (advanced), Korean (beginner), and Latin (intermediate, in theory). <a href="#ref2" title="Jump back to footnote 2.">↩</a></p>
              <p id="footnote3"><sup>3</sup> My favorite dessert is tiramisù. Respectively, my favorite main dishes are lasagna bolognese, <em>karashibi miso ramen</em> from <a href="https://kikanbo.co.jp/">Kikanbo</a> in Tokyo (wouldn't dare make this myself), and potstickers with pork and Chinese sauerkraut. <a href="#ref3" title="Jump back to footnote 3.">↩</a></p>
              <p id="footnote4"><sup>4</sup> Depiction courtesy of <a href="https://irasutoya.com/">Irasutoya</a>; unfortunately, we don't practice <a href="https://en.wikipedia.org/wiki/J%C5%ABkend%C5%8D">jukendo</a>, even though it looks stunningly cool. <a href="#ref4" title="Jump back to footnote 4.">↩</a></p>
            </div>
          </td>
        </tr>

        <tr>
          <td>
            <p align="center"><img src="/images/kendou_man.png" alt="Man" width="20%" /><img src="/images/kendou_woman.png" alt="Woman" width="20%" /><img src="/images/kendou_meisou_man.png" alt="Meisou Man" width="17%" /><img src="/images/kendou_meisou_woman.png" alt="Meisou Woman" width="17%" /></p>

            <p align="center"><img src="../images/sports_juu_kendou.png"  alt="Men!" width="40%"/><img src="../images/kendo.png" alt="Men!!" width="40%"/></p>
          </td>
        </tr>

        <tr>
          <td>
          <br>
          <p align="left">
            <font size="2">
            Last Updated: <i><b>June 17, 2024</b></i>
            </font>
              <span style="float:right;">
				<font size="2">
				<a href="https://github.com/jonbarron/jonbarron_website"><strong>Site Template</strong></a>
            </font>
			</span>
          </p>
          </td>
      </tr>

      </tbody>
    </table>

  <!-- Displays content on click -->
  <!-- Author: Steven Y. Feng @ Stanford CS -->
  <script>
    function detail_switch(click_id) {
        click_intro = click_id + '_content'
        var x = document.getElementById(click_intro);
        if (x.style.display === "none") {
            x.style.display = "block";
        } else {
            x.style.display = "none";
        }
    }
    </script>
      

  </body>
</html>
